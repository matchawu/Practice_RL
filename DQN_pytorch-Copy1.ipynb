{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_norm=1\n",
    "base_model_dump=None\n",
    "batch_size=10\n",
    "bilin_q=1\n",
    "cross_rate=0.1\n",
    "ctx='cpu'\n",
    "\n",
    "data_folder='/mnt/sda/wwj/graph_adversarial_attack/dropbox/data'\n",
    "\n",
    "dataset='pubmed'\n",
    "\n",
    "del_rate=0\n",
    "dropout=0.5\n",
    "er_p=0\n",
    "feat_dim=0\n",
    "\n",
    "feature_dim=None\n",
    "\n",
    "fold=1\n",
    "frac_meta=0\n",
    "gm='mean_field'\n",
    "hidden=0\n",
    "idx_start=None\n",
    "latent_dim=64\n",
    "learning_rate=0.01\n",
    "logfile=None\n",
    "max_c=0\n",
    "max_lv=1\n",
    "max_n=0\n",
    "meta_test=0\n",
    "min_c=0\n",
    "min_n=0\n",
    "mlp_hidden=64\n",
    "mutate_rate=0.2\n",
    "n_graphs=0\n",
    "n_hops=3\n",
    "num_class=None\n",
    "num_epochs=200\n",
    "num_instances=None\n",
    "num_mod=1\n",
    "num_steps=500000\n",
    "out_dim=0\n",
    "phase='train'\n",
    "population_size=100\n",
    "rand_att_type=None\n",
    "reward_type='binary'\n",
    "rounds=10\n",
    "save_dir='/home/wwj/scratch/results/del_edge_attack/pubmed-gcn-0.01/rl-lv-1-q-1-meta-0'\n",
    "saved_model='/mnt/sda/wwj/graph_adversarial_attack/dropbox/scratch/results/node_classification/pubmed/model-gcn-epoch-best-0.01'\n",
    "seed=1\n",
    "targeted=0\n",
    "weight_decay=0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import networkx as nx\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import networkx as nx\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "# import cPickle as cp\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_utils\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "import torch\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg.eigen.arpack import eigsh\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gcn_modules\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import networkx as nx\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "# import cPickle as cp\n",
    "import pickle as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff62cb4e9a8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(np.loadtxt(data_folder +'/'+ dataset + '/train_idx.txt', dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_graph(data_folder, dataset_str):\n",
    "    bin_file = \"{}/ind.{}.{}\".format(data_folder, dataset_str, 'graph')\n",
    "    if os.path.isfile(bin_file):\n",
    "        with open(bin_file, 'rb') as f:\n",
    "            if sys.version_info > (3, 0):\n",
    "                graph = pkl.load(f, encoding='latin1')\n",
    "            else:\n",
    "                graph = pkl.load(f)\n",
    "    else:\n",
    "        txt_file = data_folder + '/adj_list.txt'\n",
    "        graph = {}\n",
    "        with open(txt_file, 'r') as f:\n",
    "            cur_idx = 0\n",
    "            for row in f:\n",
    "                row = row.strip().split()\n",
    "                adjs = []\n",
    "                for j in range(1, len(row)):\n",
    "                    adjs.append(int(row[j]))\n",
    "                graph[cur_idx] = adjs\n",
    "                cur_idx += 1\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StaticGraph(object):\n",
    "    graph = None\n",
    "\n",
    "    @staticmethod\n",
    "    def get_gsize():\n",
    "        return torch.Size( (len(StaticGraph.graph), len(StaticGraph.graph)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_txt_data(data_folder, dataset_str):\n",
    "    idx_train = list(np.loadtxt(data_folder + '/train_idx.txt', dtype=int))\n",
    "    idx_val = list(np.loadtxt(data_folder + '/val_idx.txt', dtype=int))\n",
    "    idx_test = list(np.loadtxt(data_folder + '/test_idx.txt', dtype=int))\n",
    "    labels = np.loadtxt(data_folder + '/label.txt')\n",
    "    \n",
    "    with open(data_folder + '/meta.txt', 'r') as f:\n",
    "        num_nodes, num_class, feature_dim = [int(w) for w in f.readline().strip().split()]\n",
    "\n",
    "    graph = load_raw_graph(data_folder, dataset_str)\n",
    "    assert len(graph) == num_nodes\n",
    "    StaticGraph.graph = nx.from_dict_of_lists(graph)\n",
    "    \n",
    "    row_ptr = []\n",
    "    col_idx = []\n",
    "    vals = []\n",
    "    with open(data_folder + '/features.txt', 'r') as f:\n",
    "        nnz = 0\n",
    "        for row in f:\n",
    "            row = row.strip().split()\n",
    "            row_ptr.append(nnz)            \n",
    "            for i in range(1, len(row)):\n",
    "                w = row[i].split(':')\n",
    "                col_idx.append(int(w[0]))\n",
    "                vals.append(float(w[1]))\n",
    "            nnz += int(row[0])\n",
    "        row_ptr.append(nnz)\n",
    "    assert len(col_idx) == len(vals) and len(vals) == nnz and len(row_ptr) == num_nodes + 1\n",
    "\n",
    "    features = sp.csr_matrix((vals, col_idx, row_ptr), shape=(num_nodes, feature_dim))\n",
    "    \n",
    "    return preprocess_features(features), labels, idx_train, idx_val, idx_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(features):\n",
    "    \"\"\"Row-normalize feature matrix and convert to tuple representation\"\"\"\n",
    "    rowsum = np.array(features.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    features = r_mat_inv.dot(features)    \n",
    "    sp_tuple = sparse_to_tuple(features)\n",
    "    idxes = torch.LongTensor(sp_tuple[0]).transpose(0, 1).contiguous()\n",
    "    values = torch.Tensor(sp_tuple[1].astype(np.float32))\n",
    "\n",
    "    mat = torch.sparse.FloatTensor(idxes, values, torch.Size(sp_tuple[2]))\n",
    "    if ctx == 'gpu':\n",
    "        mat = mat.cuda()\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_to_tuple(sparse_mx):\n",
    "    \"\"\"Convert sparse matrix to tuple representation.\"\"\"\n",
    "    def to_tuple(mx):\n",
    "        if not sp.isspmatrix_coo(mx):\n",
    "            mx = mx.tocoo()\n",
    "        coords = np.vstack((mx.row, mx.col)).transpose()\n",
    "        values = mx.data\n",
    "        shape = mx.shape\n",
    "        return coords, values, shape\n",
    "\n",
    "    if isinstance(sparse_mx, list):\n",
    "        for i in range(len(sparse_mx)):\n",
    "            sparse_mx[i] = to_tuple(sparse_mx[i])\n",
    "    else:\n",
    "        sparse_mx = to_tuple(sparse_mx)\n",
    "\n",
    "    return sparse_mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels, _, idx_val, idx_test = load_txt_data(data_folder + '/' + dataset, dataset)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[    0,     0,     0,  ..., 19716, 19716, 19716],\n",
       "                       [  394,   384,   382,  ...,    16,     7,     1]]),\n",
       "       values=tensor([0.0283, 0.0162, 0.0125,  ..., 0.0104, 0.0030, 0.0145]),\n",
       "       size=(19717, 500), nnz=988031, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = Variable( features )\n",
    "labels = Variable( torch.LongTensor( np.argmax(labels, axis=1) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ctx == 'gpu':\n",
    "    labels = labels.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_base_model():\n",
    "    assert saved_model is not None\n",
    "    with open('%s-args.pkl' % saved_model, 'rb') as f:\n",
    "        base_args = pkl.load(f)\n",
    "    if 'mean_field' in saved_model: # XX\n",
    "        mod = S2VNodeClassifier\n",
    "    elif 'gcn' in saved_model: # this \n",
    "        mod = GCNModule\n",
    "\n",
    "    gcn = mod(**vars(base_args))\n",
    "    if ctx == 'gpu':\n",
    "        gcn = gcn.cuda()\n",
    "    gcn.load_state_dict(torch.load(saved_model+ '.model'))\n",
    "    gcn.eval()\n",
    "    return gcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolution(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.Tensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        weights_init(self)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        if input.data.is_sparse:\n",
    "            support = gnn_spmm(input, self.weight)\n",
    "        else:\n",
    "            support = torch.mm(input, self.weight)\n",
    "        \n",
    "        output = gnn_spmm(adj, support)\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'\n",
    "\n",
    "class GCNModule(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(GCNModule, self).__init__()\n",
    "        self.gc1 = GraphConvolution(kwargs['feature_dim'], kwargs['latent_dim'])\n",
    "        self.gc2 = GraphConvolution(kwargs['latent_dim'], kwargs['num_class'])\n",
    "        self.dropout_rate = kwargs['dropout']\n",
    "        self.norm_tool = GraphNormTool(kwargs['adj_norm'], 'gcn')\n",
    "\n",
    "    def forward(self, x, adj, node_selector = None, labels = None, avg_loss = True):\n",
    "        x = F.relu(self.gc1(x, adj))\n",
    "        x = F.dropout(x, self.dropout_rate, training=self.training)\n",
    "        x = self.gc2(x, adj)        \n",
    "        logits = F.log_softmax(x, dim=1)\n",
    "\n",
    "        if node_selector is not None:\n",
    "            logits = logits[node_selector]\n",
    "        \n",
    "        if labels is not None:\n",
    "            if node_selector is not None:\n",
    "                labels = labels[node_selector]\n",
    "            loss = F.nll_loss(logits, labels, reduce=avg_loss)\n",
    "            pred = logits.data.max(1, keepdim=True)[1]\n",
    "            acc = pred.eq(labels.data.view_as(pred)).cpu()\n",
    "            return pred, loss, acc\n",
    "        else:\n",
    "            return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glorot_uniform(t):\n",
    "    if len(t.size()) == 2:\n",
    "        fan_in, fan_out = t.size()\n",
    "    elif len(t.size()) == 3:\n",
    "        # out_ch, in_ch, kernel for Conv 1\n",
    "        fan_in = t.size()[1] * t.size()[2]\n",
    "        fan_out = t.size()[0] * t.size()[2]\n",
    "    else:\n",
    "        fan_in = np.prod(t.size())\n",
    "        fan_out = np.prod(t.size())\n",
    "\n",
    "    limit = np.sqrt(6.0 / (fan_in + fan_out))\n",
    "    t.uniform_(-limit, limit)\n",
    "\n",
    "def _param_init(m):\n",
    "    if isinstance(m, Parameter):\n",
    "        glorot_uniform(m.data)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        m.bias.data.zero_()\n",
    "        glorot_uniform(m.weight.data)\n",
    "\n",
    "def weights_init(m):\n",
    "    for p in m.modules():\n",
    "        if isinstance(p, nn.ParameterList):\n",
    "            for pp in p:\n",
    "                _param_init(pp)\n",
    "        else:\n",
    "            _param_init(p)\n",
    "\n",
    "    for name, p in m.named_parameters():\n",
    "        if not '.' in name: # top-level parameters\n",
    "            _param_init(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphNormTool(object):\n",
    "    def __init__(self, adj_norm, gm):\n",
    "        self.adj_norm = adj_norm\n",
    "        self.gm = gm\n",
    "        g = StaticGraph.graph\n",
    "\n",
    "        edges = np.array(g.edges(), dtype=np.int64)\n",
    "        rev_edges = np.array([edges[:, 1], edges[:, 0]], dtype=np.int64)\n",
    "        self_edges = np.array([range(len(g)), range(len(g))], dtype=np.int64)\n",
    "\n",
    "        edges = np.hstack((edges.T, rev_edges, self_edges))\n",
    "\n",
    "        idxes = torch.LongTensor(edges)\n",
    "        values = torch.ones(idxes.size()[1])\n",
    "\n",
    "        self.raw_adj = torch.sparse.FloatTensor(idxes, values, StaticGraph.get_gsize())\n",
    "        if ctx == 'gpu':\n",
    "            self.raw_adj = self.raw_adj.cuda()\n",
    "        \n",
    "        self.normed_adj = self.raw_adj.clone()\n",
    "        if self.adj_norm:\n",
    "            if self.gm == 'gcn':\n",
    "                GraphLaplacianNorm(self.normed_adj)\n",
    "            else:\n",
    "                GraphDegreeNorm(self.normed_adj)\n",
    "\n",
    "    def norm_extra(self, added_adj = None):\n",
    "        if added_adj is None:\n",
    "            return self.normed_adj\n",
    "\n",
    "        new_adj = self.raw_adj + added_adj\n",
    "        if self.adj_norm:\n",
    "            if self.gm == 'gcn':\n",
    "                GraphLaplacianNorm(new_adj)\n",
    "            else:\n",
    "                GraphDegreeNorm(new_adj)\n",
    "        return new_adj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GraphLaplacianNorm(raw_adj):\n",
    "    ones = torch.ones(raw_adj.size()[0], 1)\n",
    "    if raw_adj.is_cuda:\n",
    "        ones = ones.cuda()\n",
    "    norm = torch.mm(raw_adj, ones) ** 0.5\n",
    "    indices = raw_adj._indices()\n",
    "    values = raw_adj._values()\n",
    "    if not values.is_cuda:\n",
    "        my_lib.graph_laplacian_norm(indices, values, norm)\n",
    "    else:\n",
    "        my_lib.graph_laplacian_norm_cuda(indices, values, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_lib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-711908760b85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_base_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-69-46b083b0da0a>\u001b[0m in \u001b[0;36mload_base_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGCNModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'gpu'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mgcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-72-2402e27a9f3a>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraphConvolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'latent_dim'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dropout'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_tool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraphNormTool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'adj_norm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gcn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_selector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-83-1746d032dc1b>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, adj_norm, gm)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj_norm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'gcn'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 \u001b[0mGraphLaplacianNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormed_adj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mGraphDegreeNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormed_adj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-85-5f10d23b19a5>\u001b[0m in \u001b[0;36mGraphLaplacianNorm\u001b[0;34m(raw_adj)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_adj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mmy_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_laplacian_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmy_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_laplacian_norm_cuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'my_lib' is not defined"
     ]
    }
   ],
   "source": [
    "base_model = load_base_model()\n",
    "base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_setup():\n",
    "    features, labels, _, idx_val, idx_test = load_txt_data(cmd_args.data_folder + '/' + cmd_args.dataset, cmd_args.dataset)    \n",
    "    features = Variable( features )\n",
    "    labels = Variable( torch.LongTensor( np.argmax(labels, axis=1) ) )\n",
    "    if cmd_args.ctx == 'gpu':\n",
    "        labels = labels.cuda()\n",
    "\n",
    "    base_model = load_base_model() # load base model\n",
    "    run_test(base_model, features, Variable( base_model.norm_tool.normed_adj ), idx_test, labels)\n",
    "\n",
    "    dict_of_lists = load_raw_graph(cmd_args.data_folder + '/' + cmd_args.dataset, cmd_args.dataset)\n",
    "\n",
    "    return features, labels, idx_val, idx_test, base_model, dict_of_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

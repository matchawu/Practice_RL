{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Use device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gym\n",
    "import math\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import sys\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Use device: %s\"%device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please tune the hyperparameters\n",
    "train_ep = 800\n",
    "mem_capacity = 65000\n",
    "batch_size = 128\n",
    "lr = 0.00025\n",
    "gamma = 0.999\n",
    "epsilon_start = 1.0\n",
    "epsilon_final = 0.1\n",
    "epsilon_decay = 1000000\n",
    "target_step = 10000\n",
    "eval_per_ep = 10\n",
    "save_per_ep = 50\n",
    "save_dir = \"./HW3/model\"\n",
    "log_file = \"./HW3/log.txt\"\n",
    "load_model = None\n",
    "train = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward', 'done'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "        \n",
    "    def push(self, *args):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "        \n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(4, 32, kernel_size=8, stride=4)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        def conv2d_size_out(size, kernel_size = 3, stride = 1):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w,8,4),4,2),3,1)\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h,8,4),4,2),3,1)\n",
    "        linear_input_size = convw * convh * 64\n",
    "        \n",
    "        self.fc = nn.Linear(linear_input_size, 512)\n",
    "        self.head = nn.Linear(512, outputs)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.bn1(self.conv1(x)))\n",
    "        x = F.leaky_relu(self.bn2(self.conv2(x)))\n",
    "        x = F.leaky_relu(self.bn3(self.conv3(x)))\n",
    "        x = F.leaky_relu(self.fc(x.view(x.size(0), -1)))\n",
    "        return self.head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [\"NOOP\", \"UP\", \"DOWN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(object):\n",
    "    def __init__(self):\n",
    "        self.BATCH_SIZE = batch_size\n",
    "        self.GAMMA = gamma\n",
    "        self.EPS_START = epsilon_start\n",
    "        self.EPS_END = epsilon_final\n",
    "        self.EPS_DECAY = epsilon_decay\n",
    "        self.LEARN_RATE = lr\n",
    "        self.TARGET_UPDATE = target_step\n",
    "\n",
    "        self.action_dim = 3\n",
    "        self.state_dim = (84,84)\n",
    "        self.epsilon = 0.0\n",
    "        self.update_count = 0\n",
    "        \n",
    "        self.policy_net = CNN(self.state_dim[0], self.state_dim[1], self.action_dim).to(device) # policy network\n",
    "        self.target_net = CNN(self.state_dim[0], self.state_dim[1], self.action_dim).to(device) # target network\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "        self.target_net.eval()\n",
    "        self.optimizer = optim.RMSprop(self.policy_net.parameters(), lr=self.LEARN_RATE)\n",
    "        \n",
    "        self.memory = ReplayMemory(mem_capacity)\n",
    "        self.interaction_steps = 0\n",
    "\n",
    "    def select_action(self, state):\n",
    "        self.interaction_steps += 1\n",
    "        self.epsilon = self.EPS_END + np.maximum( (self.EPS_START-self.EPS_END) * (1 - self.interaction_steps/self.EPS_DECAY), 0)\n",
    "        if random.random() < self.epsilon:\n",
    "            return torch.tensor([[np.random.choice(np.arange(0, 3), p=[0.3, 0.6, 0.1])]], device=device, dtype=torch.long)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                return self.policy_net(state).max(1)[1].view(1, 1)\n",
    "\n",
    "    def evaluate_action(self, state, rand=0.1):\n",
    "        if random.random() < rand:\n",
    "            return torch.tensor([[np.random.choice(np.arange(0, 3), p=[0.3, 0.6, 0.1])]], device=device, dtype=torch.long)\n",
    "        with torch.no_grad():\n",
    "            t = self.target_net(state)\n",
    "            \n",
    "            # trace and sample state\n",
    "            print_string = \"Q-value: \"+ str(t.cpu().numpy()[0]) + \\\n",
    "            \", agent's choice: \" + str(actions[t.max(1)[1].view(1, 1).cpu().numpy()[0][0]]) + \\\n",
    "            \", mean: \" + str(np.mean(t.cpu().numpy()[0]))\n",
    "            print(print_string)\n",
    "            \n",
    "            return t.max(1)[1].view(1, 1)\n",
    "\n",
    "\n",
    "    def store(self, state, action, next_state, reward, done):\n",
    "        self.memory.push(state, action, next_state, reward, done)\n",
    "\n",
    "    def update(self):\n",
    "        if len(self.memory) < self.BATCH_SIZE:\n",
    "            print(\"[Warning] Memory data less than batch sizes!\")\n",
    "            return\n",
    "        \n",
    "        transitions = self.memory.sample(self.BATCH_SIZE)\n",
    "        batch = Transition(*zip(*transitions))\n",
    "        \n",
    "        final_mask = torch.cat(batch.done)\n",
    "        non_final_next_states = torch.cat([s for s in batch.next_state if s is not None])\n",
    "        state_batch = torch.cat(batch.state)\n",
    "        action_batch = torch.cat(batch.action)\n",
    "        reward_batch = torch.cat(batch.reward)\n",
    "        \n",
    "        state_action_values = self.policy_net(state_batch).gather(1, action_batch)\n",
    "        \n",
    "        next_state_values = torch.zeros(self.BATCH_SIZE,1, device=device)\n",
    "        next_state_values[final_mask.bitwise_not()] = self.target_net(non_final_next_states).max(1, True)[0].detach()\n",
    "\n",
    "        expected_state_action_values = (next_state_values * self.GAMMA) + reward_batch\n",
    "    \n",
    "        loss = F.smooth_l1_loss(state_action_values, expected_state_action_values)\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        for param in self.policy_net.parameters():\n",
    "            param.grad.data.clamp_(-1, 1)\n",
    "        self.optimizer.step()\n",
    "\n",
    "        self.update_count += 1\n",
    "        if self.update_count % self.TARGET_UPDATE == 0:\n",
    "            self.update_target_net()\n",
    "\n",
    "        \n",
    "    def update_target_net(self):\n",
    "        with torch.no_grad():\n",
    "            self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "\n",
    "    def save_model(self, path=\".\"):\n",
    "        torch.save(self.target_net.state_dict(), path+'/q_target_checkpoint_{}.pth'.format(self.interaction_steps))\n",
    "        torch.save(self.policy_net.state_dict(), path+'/q_policy_checkpoint_{}.pth'.format(self.interaction_steps))\n",
    "\n",
    "    def restore_model(self, path):\n",
    "        self.target_net.load_state_dict(torch.load(path))\n",
    "        self.policy_net.load_state_dict(torch.load(path))\n",
    "        self.target_net.eval()\n",
    "        print(\"[Info] Restore model from '%s' !\"%path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent(object):\n",
    "    def __init__(self):\n",
    "        self.action_dim = 3\n",
    "        self.interaction_steps = 0\n",
    "\n",
    "    def select_action(self, state):\n",
    "        self.interaction_steps += 1\n",
    "        return torch.tensor( [np.random.choice(np.arange(0, 3), p=[0.3, 0.6, 0.1])], device=device, dtype=torch.long )\n",
    "\n",
    "    def evaluate_action(self, state):\n",
    "        return torch.tensor( [np.random.choice(np.arange(0, 3), p=[0.3, 0.6, 0.1])], device=device, dtype=torch.long )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_proc = T.Compose([T.ToPILImage(),\n",
    "                        T.Grayscale(), \\\n",
    "                        T.Resize((84,84), interpolation=Image.BILINEAR), \\\n",
    "                        T.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Atari(object):\n",
    "    def __init__(self, env_name=\"FreewayDeterministic-v4\", agent_history_length=4):\n",
    "        self.env = gym.make(env_name)\n",
    "        self.state = None\n",
    "        self.agent_history_length = agent_history_length\n",
    "\n",
    "    def reset(self):\n",
    "        observation = self.env.reset()\n",
    "        frame = self.image_proc(observation).to(device)\n",
    "        self.state = frame.repeat(1,4,1,1)\n",
    "        return self.state\n",
    "\n",
    "    def image_proc(self, image):\n",
    "        return frame_proc(image)\n",
    "\n",
    "    def step(self, action):\n",
    "        observation, reward, done, info = self.env.step(action)\n",
    "        frame = self.image_proc(observation).to(device)\n",
    "        next_state = torch.cat( (self.state[:, 1:, :, :], frame.unsqueeze(0)), axis=1 )\n",
    "        self.state = next_state\n",
    "        return next_state, reward, done, info\n",
    "\n",
    "    def get_render(self):\n",
    "        observation = self.env.render(mode='rgb_array')\n",
    "        return observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    num_episodes = train_ep\n",
    "    save_model_per_ep = save_per_ep\n",
    "    log_fd = open(log_file,'w')\n",
    "\n",
    "    ########## Training ##########\n",
    "    agent = DQN()\n",
    "    env = Atari()\n",
    "\n",
    "    if load_model:\n",
    "        agent.restore_model(load_model)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    global_steps = 0\n",
    "    reward_box = []\n",
    "    for i_episode in range(num_episodes):\n",
    "        episode_reward = 0\n",
    "        state = env.reset()\n",
    "\n",
    "        for _ in range(10000):\n",
    "#             env.env.render()\n",
    "            action = agent.select_action(state)\n",
    "            next_state, reward, done, _ = env.step(action.item())\n",
    "            \n",
    "            if done:\n",
    "                next_state = None\n",
    "\n",
    "            agent.memory.push(  state, \\\n",
    "                                action, \\\n",
    "                                next_state, \\\n",
    "                                torch.tensor([[reward]], device=device), \\\n",
    "                                torch.tensor([done], device=device, dtype=torch.bool))\n",
    "            state = next_state\n",
    "            episode_reward += reward\n",
    "            global_steps += 1 \n",
    "\n",
    "            if global_steps > 50000:\n",
    "                agent.update()\n",
    "\n",
    "            if done:\n",
    "                print(\"Episode: %6d, interaction_steps: %6d, reward: %2d, epsilon: %f\"%(i_episode+1, agent.interaction_steps, episode_reward, agent.epsilon))\n",
    "                reward_box.append(episode_reward)\n",
    "                log_fd.write(\"Episode: %6d, interaction_steps: %6d, reward: %2d, epsilon: %f\\n\"%(i_episode+1, agent.interaction_steps, episode_reward, agent.epsilon))\n",
    "                break\n",
    "\n",
    "        if i_episode % save_model_per_ep == 0:\n",
    "            agent.save_model(save_dir)\n",
    "            print(\"[Info] Save model at '%s' !\"%save_dir)\n",
    "\n",
    "        if i_episode % eval_per_ep == 0:\n",
    "            test_env = Atari()\n",
    "            test_times = 5\n",
    "\n",
    "            average_reward = 0.0\n",
    "            for t_ep in range(test_times):\n",
    "                episode_reward = 0.0\n",
    "                state = test_env.reset()\n",
    "                for _ in range(10000):\n",
    "                    action = agent.evaluate_action(state)\n",
    "                    state, reward, done, _ = test_env.step(action.item())\n",
    "                    episode_reward += reward\n",
    "            average_reward += episode_reward\n",
    "            \n",
    "            print(\"Evaluation: True, episode: %6d, interaction_steps: %6d, evaluate reward: %2d\"%(i_episode+1, agent.interaction_steps, average_reward/test_times))\n",
    "            log_fd.write(\"Evaluation: True, episode: %6d, interaction_steps: %6d, evaluate reward: %2d\"%(i_episode+1, agent.interaction_steps, average_reward/test_times))\n",
    "    \n",
    "    log_fd.close()\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title(\"DQN episode total reward\")\n",
    "    plt.plot(reward_box)\n",
    "    plt.xlabel(\"episode\")\n",
    "    plt.ylabel(\"reward\")\n",
    "    plt.savefig('HW3/training_reward.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(path):\n",
    "    agent = DQN()\n",
    "    env = Atari()\n",
    "    test_epsilon = epsilon_final\n",
    "    \n",
    "#     if args.load_model:\n",
    "#         agent.restore_model(args.load_model)\n",
    "#     else:\n",
    "#         test_epsilon = 1.0\n",
    "    agent.restore_model(path)\n",
    "      \n",
    "    reward_box = []\n",
    "    for i_episode in range(200):\n",
    "        episode_reward = 0\n",
    "        state = env.reset()\n",
    "\n",
    "        for _ in range(10000):\n",
    "            env.env.render() # show atari playing screen\n",
    "            action = agent.evaluate_action(state, test_epsilon)\n",
    "            \n",
    "            sys.stdin.readline() # wait until keyboard action for saving screenshots\n",
    "            \n",
    "            next_state, reward, done, _ = env.step(action.item())\n",
    "            state = next_state\n",
    "            episode_reward += reward\n",
    "\n",
    "            if done:\n",
    "                print(\"Episode: %6d, interaction_steps: %6d, reward: %2d, epsilon: %f\"%(i_episode, agent.interaction_steps, episode_reward, test_epsilon))\n",
    "                reward_box.append(episode_reward)\n",
    "                break\n",
    "    reward_np = np.array(reward_box)\n",
    "    print(\"mean: \", np.mean(reward_np))\n",
    "    print(\"std: \", np.std(reward_np))\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title(\"DQN episode test reward\")\n",
    "    plt.plot(reward_box)\n",
    "    plt.xlabel(\"episode\")\n",
    "    plt.ylabel(\"reward\")\n",
    "    plt.savefig('HW3/testing_reward.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n",
      "Q-value: [ 0.0092174  -0.00056365  0.01801455], agent's choice: DOWN, mean: 0.008889434\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-76895151800d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                     \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                     \u001b[0mepisode_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0maverage_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mepisode_reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-e824d987c3af>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_proc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-e824d987c3af>\u001b[0m in \u001b[0;36mimage_proc\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mimage_proc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mframe_proc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \"\"\"\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch import nn\n",
    "from torch import autograd\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# dataset\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "\n",
    "\n",
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNConv, self).__init__(aggr='add')  # \"Add\" aggregation (Step 5).\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        # Step 1: Add self-loops to the adjacency matrix.\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # Step 2: Linearly transform node feature matrix.\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Step 3: Compute normalization.\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        # Step 4-5: Start propagating messages.\n",
    "        return self.propagate(edge_index, x=x, norm=norm)\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # x_j has shape [E, out_channels]\n",
    "\n",
    "        # Step 4: Normalize node features.\n",
    "        return norm.view(-1, 1) * x_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset[0].x\n",
    "feature_num = dataset.num_features\n",
    "hidden_num = 16\n",
    "label_num = dataset.num_classes\n",
    "edge_index = dataset[0].edge_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module): # GCN\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(feature_num, hidden_num)\n",
    "        self.conv2 = GCNConv(hidden_num, label_num)\n",
    "        self.act = torch.nn.Softmax()\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.act(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "acc:  0.1357\n",
      "loss:  0.0139\n",
      "1\n",
      "acc:  0.1929\n",
      "loss:  0.0138\n",
      "2\n",
      "acc:  0.2714\n",
      "loss:  0.0138\n",
      "3\n",
      "acc:  0.5214\n",
      "loss:  0.0137\n",
      "4\n",
      "acc:  0.6214\n",
      "loss:  0.0136\n",
      "5\n",
      "acc:  0.6571\n",
      "loss:  0.0136\n",
      "6\n",
      "acc:  0.7000\n",
      "loss:  0.0135\n",
      "7\n",
      "acc:  0.7500\n",
      "loss:  0.0134\n",
      "8\n",
      "acc:  0.7857\n",
      "loss:  0.0132\n",
      "9\n",
      "acc:  0.8286\n",
      "loss:  0.0131\n",
      "10\n",
      "acc:  0.8571\n",
      "loss:  0.0130\n",
      "11\n",
      "acc:  0.8929\n",
      "loss:  0.0128\n",
      "12\n",
      "acc:  0.8929\n",
      "loss:  0.0127\n",
      "13\n",
      "acc:  0.9000\n",
      "loss:  0.0125\n",
      "14\n",
      "acc:  0.9143\n",
      "loss:  0.0123\n",
      "15\n",
      "acc:  0.9214\n",
      "loss:  0.0121\n",
      "16\n",
      "acc:  0.9429\n",
      "loss:  0.0119\n",
      "17\n",
      "acc:  0.9429\n",
      "loss:  0.0117\n",
      "18\n",
      "acc:  0.9643\n",
      "loss:  0.0115\n",
      "19\n",
      "acc:  0.9643\n",
      "loss:  0.0113\n",
      "20\n",
      "acc:  0.9643\n",
      "loss:  0.0111\n",
      "21\n",
      "acc:  0.9643\n",
      "loss:  0.0109\n",
      "22\n",
      "acc:  0.9643\n",
      "loss:  0.0107\n",
      "23\n",
      "acc:  0.9643\n",
      "loss:  0.0106\n",
      "24\n",
      "acc:  0.9643\n",
      "loss:  0.0104\n",
      "25\n",
      "acc:  0.9714\n",
      "loss:  0.0102\n",
      "26\n",
      "acc:  0.9714\n",
      "loss:  0.0100\n",
      "27\n",
      "acc:  0.9714\n",
      "loss:  0.0099\n",
      "28\n",
      "acc:  0.9714\n",
      "loss:  0.0098\n",
      "29\n",
      "acc:  0.9714\n",
      "loss:  0.0096\n",
      "30\n",
      "acc:  0.9786\n",
      "loss:  0.0095\n",
      "31\n",
      "acc:  0.9786\n",
      "loss:  0.0094\n",
      "32\n",
      "acc:  0.9786\n",
      "loss:  0.0093\n",
      "33\n",
      "acc:  0.9857\n",
      "loss:  0.0092\n",
      "34\n",
      "acc:  0.9857\n",
      "loss:  0.0092\n",
      "35\n",
      "acc:  0.9857\n",
      "loss:  0.0091\n",
      "36\n",
      "acc:  0.9857\n",
      "loss:  0.0090\n",
      "37\n",
      "acc:  0.9857\n",
      "loss:  0.0090\n",
      "38\n",
      "acc:  0.9857\n",
      "loss:  0.0089\n",
      "39\n",
      "acc:  0.9857\n",
      "loss:  0.0089\n",
      "40\n",
      "acc:  0.9857\n",
      "loss:  0.0088\n",
      "41\n",
      "acc:  0.9857\n",
      "loss:  0.0088\n",
      "42\n",
      "acc:  0.9857\n",
      "loss:  0.0087\n",
      "43\n",
      "acc:  0.9929\n",
      "loss:  0.0087\n",
      "44\n",
      "acc:  0.9929\n",
      "loss:  0.0087\n",
      "45\n",
      "acc:  0.9929\n",
      "loss:  0.0086\n",
      "46\n",
      "acc:  0.9929\n",
      "loss:  0.0086\n",
      "47\n",
      "acc:  0.9929\n",
      "loss:  0.0086\n",
      "48\n",
      "acc:  0.9929\n",
      "loss:  0.0086\n",
      "49\n",
      "acc:  0.9929\n",
      "loss:  0.0086\n",
      "50\n",
      "acc:  0.9929\n",
      "loss:  0.0085\n",
      "51\n",
      "acc:  0.9929\n",
      "loss:  0.0085\n",
      "52\n",
      "acc:  0.9929\n",
      "loss:  0.0085\n",
      "53\n",
      "acc:  0.9929\n",
      "loss:  0.0085\n",
      "54\n",
      "acc:  0.9929\n",
      "loss:  0.0085\n",
      "55\n",
      "acc:  0.9929\n",
      "loss:  0.0085\n",
      "56\n",
      "acc:  0.9929\n",
      "loss:  0.0085\n",
      "57\n",
      "acc:  0.9929\n",
      "loss:  0.0085\n",
      "58\n",
      "acc:  0.9929\n",
      "loss:  0.0085\n",
      "59\n",
      "acc:  0.9929\n",
      "loss:  0.0085\n",
      "60\n",
      "acc:  0.9929\n",
      "loss:  0.0085\n",
      "61\n",
      "acc:  0.9929\n",
      "loss:  0.0085\n",
      "62\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "63\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "64\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "65\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "66\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "67\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "68\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "69\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "70\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "71\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "72\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "73\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "74\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "75\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "76\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "77\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "78\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "79\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "80\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "81\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "82\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "83\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "84\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "85\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "86\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "87\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "88\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "89\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "90\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "91\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "92\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "93\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "94\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "95\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "96\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "97\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "98\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "99\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "100\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "101\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "102\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "103\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "104\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "105\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "106\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "107\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "108\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "109\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "110\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "111\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "112\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "113\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "114\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "115\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "116\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "117\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "118\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "119\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "120\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "121\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "122\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "123\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "124\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "125\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "126\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "127\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "128\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "129\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "130\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "131\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "132\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "133\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "134\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "135\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "136\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "137\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "138\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "139\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "140\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "141\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "142\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "143\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "144\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "145\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "146\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "147\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "148\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "149\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "150\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "151\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "152\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "153\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "154\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "155\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "156\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "157\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "158\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "159\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "160\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "161\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "162\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "163\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "164\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "165\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "166\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "167\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "168\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "169\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "170\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "171\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "172\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "173\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "174\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "175\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "176\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "177\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "178\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "179\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "180\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "181\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "182\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "183\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "184\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "185\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "186\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "187\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "188\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "189\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "190\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "191\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "192\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "193\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "194\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "195\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "196\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "197\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "198\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n",
      "199\n",
      "acc:  0.9929\n",
      "loss:  0.0084\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "crit = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "loss_record = list()\n",
    "acc_record = list()\n",
    "\n",
    "for epoch in range(200):\n",
    "    print(epoch)\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    data = dataset[0].to(device)\n",
    "    label = dataset[0].y.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    \n",
    "    loss = crit(output[data.train_mask], label[data.train_mask])\n",
    "    loss.backward()\n",
    "    loss_record.append(loss.item()/len(data.y[data.train_mask]))\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    pred = output.argmax(dim=1)\n",
    "    print(\"train set\")\n",
    "    acc_num = torch.eq(pred[data.train_mask],label[data.train_mask]).sum().float().item()\n",
    "    acc = acc_num/len(data.y[data.train_mask])\n",
    "    acc_record.append(acc)\n",
    "\n",
    "\n",
    "    \n",
    "    print(\"acc: \", '%.4f'%acc_record[-1], \"loss: \", '%.4f'%loss_record[-1])\n",
    "    print(\"acc: \", '%.4f'%acc_record[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc75c7d3eb8>]"
      ]
     },
     "metadata": {},
     "execution_count": 17
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (http://matplotlib.org/) -->\n<svg height=\"252.018125pt\" version=\"1.1\" viewBox=\"0 0 375.603125 252.018125\" width=\"375.603125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 252.018125 \nL 375.603125 252.018125 \nL 375.603125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 228.14 \nL 364.903125 228.14 \nL 364.903125 10.7 \nL 30.103125 10.7 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m125a3ed6c2\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.321307\" xlink:href=\"#m125a3ed6c2\" y=\"228.14\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-30\"/>\n      </defs>\n      <g transform=\"translate(42.140057 242.738437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"83.557945\" xlink:href=\"#m125a3ed6c2\" y=\"228.14\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 25 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-32\"/>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-35\"/>\n      </defs>\n      <g transform=\"translate(77.195445 242.738437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"121.794582\" xlink:href=\"#m125a3ed6c2\" y=\"228.14\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 50 -->\n      <g transform=\"translate(115.432082 242.738437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"160.03122\" xlink:href=\"#m125a3ed6c2\" y=\"228.14\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 75 -->\n      <defs>\n       <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-37\"/>\n      </defs>\n      <g transform=\"translate(153.66872 242.738437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-37\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"198.267858\" xlink:href=\"#m125a3ed6c2\" y=\"228.14\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 100 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-31\"/>\n      </defs>\n      <g transform=\"translate(188.724108 242.738437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"236.504495\" xlink:href=\"#m125a3ed6c2\" y=\"228.14\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 125 -->\n      <g transform=\"translate(226.960745 242.738437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"274.741133\" xlink:href=\"#m125a3ed6c2\" y=\"228.14\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 150 -->\n      <g transform=\"translate(265.197383 242.738437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"312.977771\" xlink:href=\"#m125a3ed6c2\" y=\"228.14\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 175 -->\n      <g transform=\"translate(303.434021 242.738437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-37\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"351.214409\" xlink:href=\"#m125a3ed6c2\" y=\"228.14\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 200 -->\n      <g transform=\"translate(341.670659 242.738437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m0bccd5933a\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m0bccd5933a\" y=\"219.939379\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.0 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-2e\"/>\n      </defs>\n      <g transform=\"translate(7.2 223.738598)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m0bccd5933a\" y=\"179.781388\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.2 -->\n      <g transform=\"translate(7.2 183.580607)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m0bccd5933a\" y=\"139.623397\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.4 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-34\"/>\n      </defs>\n      <g transform=\"translate(7.2 143.422615)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m0bccd5933a\" y=\"99.465405\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.6 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-36\"/>\n      </defs>\n      <g transform=\"translate(7.2 103.264624)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m0bccd5933a\" y=\"59.307414\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.8 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-38\"/>\n      </defs>\n      <g transform=\"translate(7.2 63.106633)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m0bccd5933a\" y=\"19.149422\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 1.0 -->\n      <g transform=\"translate(7.2 22.948641)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_16\">\n    <path clip-path=\"url(#pbd850a3656)\" d=\"M 45.321307 192.689314 \nL 46.850772 181.215602 \nL 48.380238 165.439248 \nL 49.909703 115.241759 \nL 51.439169 95.162763 \nL 52.968634 87.991693 \nL 54.4981 79.386409 \nL 56.027565 69.346912 \nL 57.557031 62.175842 \nL 59.086496 53.570558 \nL 60.615962 47.833702 \nL 62.145427 40.662632 \nL 63.674893 40.662632 \nL 65.204358 39.228418 \nL 66.733824 36.35999 \nL 68.263289 34.925776 \nL 69.792755 30.623134 \nL 71.32222 30.623134 \nL 72.851686 26.320492 \nL 82.028479 26.320492 \nL 83.557945 24.886278 \nL 89.675807 24.886278 \nL 91.205272 23.452064 \nL 94.264203 23.452064 \nL 95.793669 22.01785 \nL 109.558858 22.01785 \nL 111.088324 20.583636 \nL 349.684943 20.583636 \nL 349.684943 20.583636 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path clip-path=\"url(#pbd850a3656)\" d=\"M 45.321307 217.14705 \nL 63.674893 217.394654 \nL 100.382065 218.128527 \nL 127.912444 218.232836 \nL 238.033961 218.254936 \nL 349.684943 218.256364 \nL 349.684943 218.256364 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 228.14 \nL 30.103125 10.7 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 364.903125 228.14 \nL 364.903125 10.7 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 228.14 \nL 364.903125 228.14 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 10.7 \nL 364.903125 10.7 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pbd850a3656\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"30.103125\" y=\"10.7\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(acc_record)\n",
    "plt.plot(loss_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([False, False, False,  ..., False, False, False]) tensor([False, False, False,  ...,  True,  True,  True])\ntensor(500) tensor(1000)\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0].val_mask, dataset[0].test_mask)\n",
    "print(dataset[0].val_mask.sum(), dataset[0].test_mask.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([False, False, False,  ..., False, False, False])"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "dataset[0].val_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "pred * dataset[0].val_mask.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}